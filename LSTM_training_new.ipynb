{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torchsummaryX # We also install a summary package to check our model's forward before training"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "to2wkosT_b3y",
        "outputId": "ce669908-036b-4d5d-fab2-eaa811f36ac5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchsummaryX in /usr/local/lib/python3.7/dist-packages (1.3.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from torchsummaryX) (1.3.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torchsummaryX) (1.11.0+cu113)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchsummaryX) (1.21.6)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torchsummaryX) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torchsummaryX) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->torchsummaryX) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->torchsummaryX) (4.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oxiZ42B4SwQ-"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tests import test_prediction, test_generation\n",
        "from tqdm import tqdm\n",
        "from torchsummaryX import summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4npd4_rFzYbd",
        "outputId": "3de9126b-53a5-4509-e1a6-db229de3ecf4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device:  cuda\n"
          ]
        }
      ],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(\"Device: \", device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x5znxQhLSwRC"
      },
      "outputs": [],
      "source": [
        "dataset = np.load('dataset/wiki.train.npy', allow_pickle=True)\n",
        "devset = np.load('dataset/wiki.valid.npy', allow_pickle=True)\n",
        "# fixtures_pred = np.load('fixtures/prediction.npz')  # dev\n",
        "# fixtures_gen = np.load('fixtures/generation.npy')  # dev\n",
        "# fixtures_pred_test = np.load('fixtures/prediction_test.npz')  # test\n",
        "# fixtures_gen_test = np.load('fixtures/generation_test.npy')  # test\n",
        "vocab = np.load('dataset/vocab.npy')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# fixtures_pred['inp'][1].shape"
      ],
      "metadata": {
        "id": "Vs7xCPp1BnPm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iVwRb0dwukvf",
        "outputId": "c0e4d292-60b6-4cdd-9b51-190a46b31aec"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(579,)"
            ]
          },
          "metadata": {},
          "execution_count": 139
        }
      ],
      "source": [
        "vocab.shape\n",
        "dataset.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ry7Qj4NjPJmf",
        "outputId": "605fbba8-c632-4033-bd38-0f62794d5336"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OZNrJ8XvSwRF"
      },
      "outputs": [],
      "source": [
        "# data loader\n",
        "\n",
        "class LanguageModelDataLoader(DataLoader):\n",
        "\n",
        "    def __init__(self, dataset, batch_size, shuffle=True, seq_len=3):\n",
        "        \n",
        "        self.dataset = dataset\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.seq_len = seq_len\n",
        "        \n",
        "        # if self.shuffle:\n",
        "        #     np.random.shuffle(self.dataset)\n",
        "        # self.dataset = np.concatenate(self.dataset)\n",
        "    \n",
        "    def __len__(self) -> int:\n",
        "        return len(self.dataset) // ((self.seq_len + 1) * self.batch_size)\n",
        "\n",
        "\n",
        "    def __iter__(self):\n",
        "\n",
        "        for i in range(0, len(self.dataset), (self.seq_len + 1) * self.batch_size):\n",
        "            input = []\n",
        "            label = []\n",
        "            for b in range(self.batch_size):\n",
        "                idx = i + b*(self.seq_len + 1)\n",
        "\n",
        "                input_1 = self.dataset[idx:idx+self.seq_len]\n",
        "                label_1 = self.dataset[idx+1:idx+1+self.seq_len]\n",
        "                # print(input_1.shape)\n",
        "                if len(input_1) == len(label_1) == self.seq_len:\n",
        "                    input.append(input_1)\n",
        "                    label.append(label_1)\n",
        "                    \n",
        "            input = torch.LongTensor(input)\n",
        "            label = torch.LongTensor(label)\n",
        "            \n",
        "            if input.size(dim=0) != 0:\n",
        "                yield (input, label)\n",
        "        \n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsjHECCEukvh",
        "outputId": "47192dd5-7dd1-4ed4-983b-007ce4e2b589"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 10]) torch.Size([3, 10])\n"
          ]
        }
      ],
      "source": [
        "train_loader = LanguageModelDataLoader(dataset=dataset, batch_size=3, seq_len=10)\n",
        "for i, l in train_loader:\n",
        "    print(i.size(), l.size())\n",
        "    break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zt-7YsTYSwRI"
      },
      "outputs": [],
      "source": [
        "# model\n",
        "\n",
        "class LanguageModel(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, seq_len):\n",
        "        super(LanguageModel, self).__init__()\n",
        "        \n",
        "        self.emb = nn.Embedding(vocab_size, 256)\n",
        "        self.lstm = nn.LSTM(input_size=256, hidden_size=512, num_layers=3, batch_first=True)\n",
        "        self.linear1 = nn.Linear(in_features=512, out_features=256)\n",
        "        self.act = nn.LeakyReLU()\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        self.linear2 = nn.Linear(in_features=256, out_features=vocab_size)\n",
        "        self.logsoftmax = nn.LogSoftmax(dim=2)\n",
        "        self.emb.weight = self.linear2.weight\n",
        "\n",
        "    def forward(self, x):\n",
        "        # print(x.size())\n",
        "        out = self.emb(x)\n",
        "        # print(out.size())\n",
        "        out, _ = self.lstm(out)\n",
        "        # print(out.size())\n",
        "        out = self.linear1(out)\n",
        "        out = self.act(out)\n",
        "        out = self.dropout(out)\n",
        "        out = self.linear2(out)\n",
        "\n",
        "        # print(out.size())\n",
        "        out = self.logsoftmax(out)\n",
        "        \n",
        "        return out\n",
        "\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kIvZOIfjSwRK"
      },
      "outputs": [],
      "source": [
        "# model trainer\n",
        "\n",
        "class LanguageModelTrainer:\n",
        "    def __init__(self, model, loader, max_epochs=1, run_id='exp'):\n",
        "\n",
        "        self.model = model\n",
        "        self.loader = loader\n",
        "        self.train_losses = []\n",
        "        self.val_losses = []\n",
        "        self.predictions = []\n",
        "        self.predictions_test = []\n",
        "        self.generated_logits = []\n",
        "        self.generated = []\n",
        "        self.generated_logits_test = []\n",
        "        self.generated_test = []\n",
        "        self.epochs = 0\n",
        "        self.max_epochs = max_epochs\n",
        "        self.run_id = run_id\n",
        "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "        \n",
        "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr = 2e-3, weight_decay=1e-4)\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "        # self.scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(self.optimizer, patience=2, factor=0.8)\n",
        "        self.scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(self.optimizer, T_max=(len(self.loader) * 10))\n",
        "\n",
        "\n",
        "    def train(self):\n",
        "        self.model.train() # set to training mode\n",
        "        epoch_loss = 0\n",
        "        num_batches = 0\n",
        "        batch_bar = tqdm(total=len(self.loader), dynamic_ncols=True, leave=False, position=0, desc='Train') \n",
        "\n",
        "        for batch_num, (inputs, targets) in enumerate(self.loader):\n",
        "            epoch_loss += float(self.train_batch(inputs, targets))\n",
        "            batch_bar.set_postfix(\n",
        "                loss=\"{:.04f}\".format(float(epoch_loss / (batch_num + 1))),\n",
        "                lr=\"{:.04f}\".format(float(self.optimizer.param_groups[0]['lr']))\n",
        "            )\n",
        "            batch_bar.update()\n",
        "        batch_bar.close()\n",
        "        epoch_loss = epoch_loss / (batch_num + 1)\n",
        "        self.epochs += 1\n",
        "        print('[TRAIN]  Epoch [%d/%d]   Loss: %.4f'\n",
        "                      % (self.epochs, self.max_epochs, epoch_loss))\n",
        "        self.train_losses.append(epoch_loss)\n",
        "\n",
        "    def train_batch(self, inputs, targets):\n",
        "\n",
        "        self.optimizer.zero_grad()\n",
        "        inputs = inputs.long().to(self.device)\n",
        "        targets = targets.long().to(self.device)\n",
        "\n",
        "        outputs = self.model(inputs)\n",
        "\n",
        "        loss = self.criterion(torch.transpose(outputs, 1, 2), targets)\n",
        "\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "        self.scheduler.step()\n",
        "\n",
        "        return float(loss)\n",
        "\n",
        "    \n",
        "    def test(self):\n",
        "        self.model.eval() # set to eval mode\n",
        "        predictions = TestLanguageModel.prediction(fixtures_pred['inp'], self.model) # get predictions\n",
        "        self.predictions.append(predictions)\n",
        "        generated_logits = TestLanguageModel.generation(fixtures_gen, 10, self.model) # generated predictions for 10 words\n",
        "        generated_logits_test = TestLanguageModel.generation(fixtures_gen_test, 10, self.model)\n",
        "        nll = test_prediction(predictions, fixtures_pred['out'])\n",
        "        generated = test_generation(fixtures_gen, generated_logits, vocab)\n",
        "        generated_test = test_generation(fixtures_gen_test, generated_logits_test, vocab)\n",
        "        self.val_losses.append(nll)\n",
        "        \n",
        "        self.generated.append(generated)\n",
        "        self.generated_test.append(generated_test)\n",
        "        self.generated_logits.append(generated_logits)\n",
        "        self.generated_logits_test.append(generated_logits_test)\n",
        "        \n",
        "        # generate predictions for test data\n",
        "        predictions_test = TestLanguageModel.prediction(fixtures_pred_test['inp'], self.model) # get predictions\n",
        "        self.predictions_test.append(predictions_test)\n",
        "            \n",
        "        print('[VAL]  Epoch [%d/%d]   Loss: %.4f'\n",
        "                      % (self.epochs, self.max_epochs, nll))\n",
        "        return nll\n",
        "\n",
        "    def save(self):\n",
        "        model_path = os.path.join('/content/drive/My Drive/experiments', self.run_id, 'model-{}.pkl'.format(self.epochs))\n",
        "        torch.save({'state_dict': self.model.state_dict()},\n",
        "            model_path)\n",
        "        # np.save(os.path.join('/content/drive/My Drive/experiments', self.run_id, 'predictions-{}.npy'.format(self.epochs)), self.predictions[-1])\n",
        "        # np.save(os.path.join('/content/drive/My Drive/experiments', self.run_id, 'predictions-test-{}.npy'.format(self.epochs)), self.predictions_test[-1])\n",
        "        # np.save(os.path.join('/content/drive/My Drive/experiments', self.run_id, 'generated_logits-{}.npy'.format(self.epochs)), self.generated_logits[-1])\n",
        "        # np.save(os.path.join('/content/drive/My Drive/experiments', self.run_id, 'generated_logits-test-{}.npy'.format(self.epochs)), self.generated_logits_test[-1])\n",
        "        # with open(os.path.join('/content/drive/My Drive/experiments', self.run_id, 'generated-{}.txt'.format(self.epochs)), 'w') as fw:\n",
        "        #     fw.write(self.generated[-1])\n",
        "        # with open(os.path.join('/content/drive/My Drive/experiments', self.run_id, 'generated-{}-test.txt'.format(self.epochs)), 'w') as fw:\n",
        "        #     fw.write(self.generated_test[-1])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xPI7_kZRSwRN"
      },
      "outputs": [],
      "source": [
        "class TestLanguageModel:\n",
        "    def prediction(inp, model):\n",
        "\n",
        "        inp = torch.LongTensor(inp).to(device)\n",
        "        with torch.no_grad():\n",
        "            output = model(inp)\n",
        "            # print(output.size())\n",
        "        scores = output[:, -1, :].cpu().numpy()\n",
        "        # print(scores.shape)\n",
        "        return scores\n",
        "        \n",
        "        \n",
        "    def generation(inp, forward, model):\n",
        "      \n",
        "        generated_output = []\n",
        "        for i in range(forward):\n",
        "            output = TestLanguageModel.prediction(inp, model)\n",
        "            output_pred = np.argmax(output, axis=1).reshape((-1,1))\n",
        "            \n",
        "            if output_pred[0][0] == 1419:\n",
        "                indices = np.argsort(output, axis=1)[::-1]\n",
        "                # print(indices)\n",
        "                output_pred = indices[:, 1].reshape((-1,1))\n",
        "            # print(output_pred)\n",
        "\n",
        "            generated_output.append(output_pred)\n",
        "\n",
        "            inp = inp[:, 1:]\n",
        "            inp = np.concatenate([inp, output_pred], axis=1)\n",
        "        generated_output = np.concatenate(generated_output, axis=1)\n",
        "        return generated_output\n",
        "\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TiUrjbEjSwRQ"
      },
      "outputs": [],
      "source": [
        "NUM_EPOCHS = 100\n",
        "BATCH_SIZE = 100\n",
        "SEQ_LEN = 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2HCVG5YISwRW",
        "outputId": "ed0fcfdd-dda5-4720-edcf-1d6e17acae32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving models, predictions, and generated words to /content/drive/My Drive/experiments/1653254080\n"
          ]
        }
      ],
      "source": [
        "run_id = str(int(time.time()))\n",
        "if not os.path.exists('/content/drive/My Drive/experiments'):\n",
        "    os.mkdir('/content/drive/My Drive/experiments')\n",
        "os.mkdir('/content/drive/My Drive/experiments/%s' % run_id)\n",
        "print(\"Saving models, predictions, and generated words to /content/drive/My Drive/experiments/%s\" % run_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DbHH6zXTSwRa",
        "outputId": "767d80dd-79f5-4a26-e9eb-688fcd5916c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([100, 8]) torch.Size([100, 8])\n",
            "=================================================================\n",
            "              Kernel Shape     Output Shape     Params  Mult-Adds\n",
            "Layer                                                            \n",
            "0_emb         [256, 33278]    [100, 8, 256]  8.519168M  8.519168M\n",
            "1_lstm                   -    [100, 8, 512]  5.779456M  5.767168M\n",
            "2_linear1       [512, 256]    [100, 8, 256]   131.328k   131.072k\n",
            "3_act                    -    [100, 8, 256]          -          -\n",
            "4_dropout                -    [100, 8, 256]          -          -\n",
            "5_linear2     [256, 33278]  [100, 8, 33278]  8.552446M  8.519168M\n",
            "6_logsoftmax             -  [100, 8, 33278]          -          -\n",
            "-----------------------------------------------------------------\n",
            "                          Totals\n",
            "Total params          22.982398M\n",
            "Trainable params      22.982398M\n",
            "Non-trainable params         0.0\n",
            "Mult-Adds             22.936576M\n",
            "=================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchsummaryX/torchsummaryX.py:101: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
            "  df_sum = df.sum()\n"
          ]
        }
      ],
      "source": [
        "model = LanguageModel(len(vocab), SEQ_LEN)\n",
        "loader = LanguageModelDataLoader(dataset=dataset, batch_size=BATCH_SIZE, shuffle=True, seq_len=SEQ_LEN)\n",
        "for x, lx in loader:\n",
        "    print(x.size(), lx.size())\n",
        "    break\n",
        "summary(model, x)\n",
        "model = model.to(device)\n",
        "# print(len(loader))\n",
        "trainer = LanguageModelTrainer(model=model, loader=loader, max_epochs=NUM_EPOCHS, run_id=run_id)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7D8wTJkBSwRc",
        "outputId": "21e412ac-0851-4984-8024-fa71fbdab93e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]  Epoch [1/100]   Loss: 8.9420\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]  Epoch [2/100]   Loss: 8.5308\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]  Epoch [3/100]   Loss: 8.3838\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]  Epoch [4/100]   Loss: 8.2829\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]  Epoch [5/100]   Loss: 8.1619\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]  Epoch [6/100]   Loss: 8.0664\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]  Epoch [7/100]   Loss: 7.9898\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]  Epoch [8/100]   Loss: 7.9509\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]  Epoch [9/100]   Loss: 7.8520\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]  Epoch [10/100]   Loss: 7.8432\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]  Epoch [11/100]   Loss: 7.8425\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]  Epoch [12/100]   Loss: 7.8300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]  Epoch [13/100]   Loss: 7.7982\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]  Epoch [14/100]   Loss: 7.7349\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]  Epoch [15/100]   Loss: 7.7092\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]  Epoch [16/100]   Loss: 7.8080\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]  Epoch [17/100]   Loss: 7.8092\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]  Epoch [18/100]   Loss: 7.7307\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]  Epoch [19/100]   Loss: 7.6570\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]  Epoch [20/100]   Loss: 7.5157\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]  Epoch [21/100]   Loss: 7.4493\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]  Epoch [22/100]   Loss: 7.3378\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]  Epoch [23/100]   Loss: 7.2359\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]  Epoch [24/100]   Loss: 7.0769\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]  Epoch [25/100]   Loss: 6.8578\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]  Epoch [26/100]   Loss: 6.6557\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]  Epoch [27/100]   Loss: 6.4619\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]  Epoch [28/100]   Loss: 6.3638\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]  Epoch [29/100]   Loss: 6.3474\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]  Epoch [30/100]   Loss: 6.3433\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]  Epoch [31/100]   Loss: 6.3304\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]  Epoch [32/100]   Loss: 6.2919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]  Epoch [33/100]   Loss: 6.2302\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]  Epoch [34/100]   Loss: 6.1775\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]  Epoch [35/100]   Loss: 6.2369\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]  Epoch [36/100]   Loss: 6.4155\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]  Epoch [37/100]   Loss: 6.4877\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]  Epoch [38/100]   Loss: 6.5074\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]  Epoch [39/100]   Loss: 6.4002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]  Epoch [40/100]   Loss: 6.1808\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]  Epoch [41/100]   Loss: 5.9077\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]  Epoch [42/100]   Loss: 5.7330\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]  Epoch [43/100]   Loss: 5.5175\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]  Epoch [44/100]   Loss: 5.2534\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]  Epoch [45/100]   Loss: 4.9013\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]  Epoch [46/100]   Loss: 4.5966\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]  Epoch [47/100]   Loss: 4.4536\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]  Epoch [48/100]   Loss: 4.4299\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]  Epoch [49/100]   Loss: 4.4370\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]  Epoch [50/100]   Loss: 4.4330\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]  Epoch [51/100]   Loss: 4.3993\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]  Epoch [52/100]   Loss: 4.3786\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]  Epoch [53/100]   Loss: 4.3320\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]  Epoch [54/100]   Loss: 4.3432\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]  Epoch [55/100]   Loss: 4.5560\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]  Epoch [56/100]   Loss: 4.8084\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]  Epoch [57/100]   Loss: 4.7623\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]  Epoch [58/100]   Loss: 4.6854\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]  Epoch [59/100]   Loss: 4.6768\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]  Epoch [60/100]   Loss: 4.5329\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]  Epoch [61/100]   Loss: 4.2691\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]  Epoch [62/100]   Loss: 3.9969\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]  Epoch [63/100]   Loss: 3.9297\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]  Epoch [64/100]   Loss: 3.5136\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]  Epoch [65/100]   Loss: 3.0414\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]  Epoch [66/100]   Loss: 2.8817\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]  Epoch [67/100]   Loss: 2.8530\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]  Epoch [68/100]   Loss: 2.8523\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]  Epoch [69/100]   Loss: 2.8442\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]  Epoch [70/100]   Loss: 2.8156\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]  Epoch [71/100]   Loss: 2.7738\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]  Epoch [72/100]   Loss: 2.7478\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]  Epoch [73/100]   Loss: 2.7251\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]  Epoch [74/100]   Loss: 2.8022\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]  Epoch [75/100]   Loss: 2.9277\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]  Epoch [76/100]   Loss: 3.1284\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]  Epoch [77/100]   Loss: 3.4260\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]  Epoch [78/100]   Loss: 3.3286\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]  Epoch [79/100]   Loss: 3.1040\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]  Epoch [80/100]   Loss: 2.9393\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]  Epoch [81/100]   Loss: 2.7395\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]  Epoch [82/100]   Loss: 2.4707\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]  Epoch [83/100]   Loss: 2.1850\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]  Epoch [84/100]   Loss: 1.8214\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]  Epoch [85/100]   Loss: 1.7103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]  Epoch [86/100]   Loss: 1.7014\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]  Epoch [87/100]   Loss: 1.6975\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]  Epoch [88/100]   Loss: 1.6816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]  Epoch [89/100]   Loss: 1.6730\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]  Epoch [90/100]   Loss: 1.6606\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]  Epoch [91/100]   Loss: 1.6470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]  Epoch [92/100]   Loss: 1.6625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]  Epoch [93/100]   Loss: 1.7034\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]  Epoch [94/100]   Loss: 1.7782\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]  Epoch [95/100]   Loss: 1.8861\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]  Epoch [96/100]   Loss: 2.0636\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]  Epoch [97/100]   Loss: 2.1455\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]  Epoch [98/100]   Loss: 2.0895\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]  Epoch [99/100]   Loss: 1.9396\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]  Epoch [100/100]   Loss: 1.9279\n"
          ]
        }
      ],
      "source": [
        "best_nll = 1e30 \n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    trainer.train()\n",
        "    # nll = trainer.test()\n",
        "    # trainer.scheduler.step(nll)\n",
        "\n",
        "    # if nll < best_nll:\n",
        "    #     best_nll = nll\n",
        "    #     print(\"Saving model, predictions and generated output for epoch \"+str(epoch)+\" with NLL: \"+ str(best_nll))\n",
        "    trainer.save()\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z2FmDqBCSwRf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "outputId": "dac24731-8c9a-4b21-8310-211b1c614d33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'> <class 'list'>\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-97-63f99d811f08>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Training losses'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Validation losses'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epochs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'NLL'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2761\u001b[0m     return gca().plot(\n\u001b[1;32m   2762\u001b[0m         *args, scalex=scalex, scaley=scaley, **({\"data\": data} if data\n\u001b[0;32m-> 2763\u001b[0;31m         is not None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1645\u001b[0m         \"\"\"\n\u001b[1;32m   1646\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1647\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1648\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1649\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m             raise ValueError(f\"x and y must have same first dimension, but \"\n\u001b[0m\u001b[1;32m    343\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[1;32m    344\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (100,) and (0,)"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "\n",
        "plt.figure()\n",
        "a = np.arange(1, trainer.epochs + 1)\n",
        "b = trainer.train_losses\n",
        "print(type(a), type(b))\n",
        "plt.plot(a, b, label='Training losses')\n",
        "plt.plot(np.arange(1, trainer.epochs + 1), trainer.val_losses, label='Validation losses')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('NLL')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ipdbmqaGSwRh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6c4f307-e99b-4d7a-c0ff-53a44f93d26d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input | Output #0: while the group was en route , but only three were ultimately able to attack . None of them were | the first time , and the first single was released\n",
            "Input | Output #1: <unk> , where he remained on loan until 30 June 2010 . <eol> = = = Return to Manchester United | = = = <eol> The film 's first single ,\n",
            "Input | Output #2: 25 April 2013 , denoting shipments of 500 @,@ 000 copies . <eol> The song became One Direction 's fourth | single , and the film 's \" <unk> \" .\n",
            "Input | Output #3: , and Bruce R. ) one daughter ( Wendy J. <unk> ) and two grandchildren , died in <unk> , | and the <unk> <unk> . <eol> = = = <unk>\n",
            "Input | Output #4: Warrior were examples of this type . Because their armor was so heavy , they could only carry a single | . <eol> = = = <unk> = = = <eol>\n",
            "Input | Output #5: the embassy at 1 : 49 and landed on Guam at 2 : 23 ; twenty minutes later , Ambassador | , and the <unk> <unk> . <eol> = = =\n",
            "Input | Output #6: <unk> , $ 96 million USD ) . Damage was heaviest in South Korea , notably where it moved ashore | , and the <unk> <unk> <unk> , the <unk> <unk>\n",
            "Input | Output #7: The <unk> were condemned as <unk> by <unk> , who saw the riots as hampering attempts to resolve the situation | . The film was released on the Billboard Hot 100\n",
            "Input | Output #8: by a decision made by the War Office in mid @-@ 1941 , as it was considering the equipment to | the <unk> . <eol> = = = <unk> = =\n",
            "Input | Output #9: Division crossed the <unk> at a number of places and climbed the hills quietly toward the 9th Infantry river line | . The storm was the first highest @-@ selling @-@\n",
            "Input | Output #10: = <eol> = = = French VIII . Corps ( Corps <unk> ) = = = <eol> On 6 November | , the storm was the first highest @-@ selling @-@\n",
            "Input | Output #11: of the World from 9th Avenue \" . This is regarded as his most famous work . It is considered | a \" <unk> \" . <eol> = = = <unk>\n",
            "Input | Output #12:  <unk> @-@ 10 , <unk> @-@ 12 , <unk> @-@ 16 , <unk> @-@ 17  were all converted | to the <unk> of the <unk> . <eol> = =\n",
            "Input | Output #13: And now he has . \" <eol> = = Family = = <eol> <unk> lived 37 of his years in | the United States . The film was released on the\n",
            "Input | Output #14: Hell to which he has been condemned for <unk> . Eliot , in a letter to John <unk> dated 27 | , and the <unk> of the <unk> <unk> . <eol>\n",
            "Input | Output #15: Luoyang area , fulfilling his duties in domestic affairs . <eol> In the autumn of <unk> , he met Li | <unk> , and the <unk> <unk> . <eol> = =\n",
            "Input | Output #16: Power said they enjoyed Block Ball and its number of stages , but wondered how its eight <unk> of memory | , the film was \" the best @-@ selling \"\n",
            "Input | Output #17: by Lloyd F. Lonergan . The cameraman was Jacques <unk> . <eol> = = Release and reception = = <eol> | The film 's most common success of the film 's\n",
            "Input | Output #18: alone , the Austrians lost more than half their reserve artillery park , 6 @,@ 000 ( out of 8 | @.@ 4 in ) . The film was released on\n",
            "Input | Output #19: while attacking a ship at <unk> in the Dutch East Indies ; the loss was compounded by the fact that | the film was \" the best @-@ selling \" .\n",
            "Input | Output #20: first raised in 2007 by the member of parliament ( MP ) for <unk> . The gangsters may have run | the film 's \" <unk> \" . <eol> = =\n",
            "Input | Output #21: Species are also non @-@ spiny <unk> and includes both large trees with stout stems up to 30 metres ( | 1 @.@ 4 m ) . The storm was the\n",
            "Input | Output #22: \" : specific design issues with the building 's energy efficiency included the fact that the largest room in the | country 's <unk> . <eol> = = = <unk> =\n",
            "Input | Output #23: were reported to support over 300 @,@ 000 households in the Brazilian state of <unk> in 2005 , and in | the United States . The film was released on the\n",
            "Input | Output #24: port . <unk> in Vietnam also warned for the potential of heavy rainfall due to the dissipating Tropical Depression <unk> | , and the <unk> of the <unk> <unk> . <eol>\n",
            "Input | Output #25: T @-@ numbers in their tropical cyclone products . The following example is from discussion number 3 of Tropical Depression | II , and the film 's \" <unk> \" ,\n",
            "Input | Output #26: South Australia hosted the three @-@ game semi @-@ final series against the New South Wales <unk> . Both teams | are the first highest @-@ selling @-@ selling @-@ selling\n",
            "Input | Output #27: Perth from contention and secured the last finals spot for the <unk> . <eol> = = = Statistical leaders = | = = <eol> The film 's most common success of\n",
            "Input | Output #28: deemed it an \" amazing pop song \" , lauding the group 's falsetto and its \" head @-@ <unk> | \" . <eol> = = = <unk> = = =\n",
            "Input | Output #29: , but began patrolling the English Channel after <unk> @-@ 6 pioneered a route past British <unk> nets and mines | . The storm was the first highest @-@ selling @-@\n",
            "Input | Output #30: production executives to let him direct . He had already discussed the film with <unk> and Cohen , and felt | that the film was \" a \" <unk> \" .\n",
            "Input | Output #31: and Nick <unk> at Studio <unk> in Los Angeles , California , and was released on August 1 , 2006 | . <eol> = = = <unk> = = = <eol>\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print (trainer.generated[-1]) # get last generated output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HIUqp-8WCySX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09075d78-e524-47f2-a370-5c6d0491653e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp experiments/1651104403/predictions-test-10.npy predictions.npy\n",
            "cp experiments/1651104403/generated-10.txt generated.txt\n",
            "cp experiments/1651104403/generated_logits-test-10.npy generated_logits.npy\n"
          ]
        }
      ],
      "source": [
        "# !make runid=1651104403 epoch=10"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !ls"
      ],
      "metadata": {
        "id": "LJv2LNtIhMhM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae81dd6d-c9d4-4afc-a911-178c1140da61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset      fixtures\t\t   generated.txt  predictions.npy  sample_data\n",
            "experiments  generated_logits.npy  Makefile\t  __pycache__\t   tests_hw4.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference"
      ],
      "metadata": {
        "id": "OVDLH92uAvlN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = '/content/drive/My Drive/experiments/1653178725/model-11.pkl'"
      ],
      "metadata": {
        "id": "e6CFUalbhRqT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load(model_path)['state_dict'])\n",
        "model.eval()\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "irNIQR6jFo39",
        "outputId": "df32e71b-397f-4c51-ecbd-e6bbdec518e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LanguageModel(\n",
            "  (emb): Embedding(33278, 256)\n",
            "  (lstm): LSTM(256, 512, num_layers=3, batch_first=True)\n",
            "  (linear1): Linear(in_features=512, out_features=256, bias=True)\n",
            "  (act): LeakyReLU(negative_slope=0.01)\n",
            "  (dropout): Dropout(p=0.2, inplace=False)\n",
            "  (linear2): Linear(in_features=256, out_features=33278, bias=True)\n",
            "  (logsoftmax): LogSoftmax(dim=2)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_string = \"i am going to\""
      ],
      "metadata": {
        "id": "8swtFV1HBObZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def array_to_str(arr, vocab):\n",
        "    return \" \".join(vocab[a] for a in arr)\n",
        "\n",
        "def str_to_array(s, vocab):\n",
        "    words = s.split()\n",
        "    arr = []\n",
        "    for w in words:\n",
        "        print(w)\n",
        "        arr.append(np.where(vocab==w)[0][0])\n",
        "    # arr = [np.where(vocab==w)[0][0] for w in words]\n",
        "    return np.array(arr)"
      ],
      "metadata": {
        "id": "HOUV7i0aDWw1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = np.load('dataset/vocab.npy')\n",
        "np.where(vocab=='1')[0][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPAR49sSVjg0",
        "outputId": "9ea16f92-30a9-4f07-a350-bac4bd606185"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "117"
            ]
          },
          "metadata": {},
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inp_arr = str_to_array(input_string.lower(), vocab)\n",
        "prediction = TestLanguageModel.generation(inp_arr.reshape(1, -1), 1, model)\n",
        "print(prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KU38vzX8ELww",
        "outputId": "4b044c61-c8d2-4e8a-b3bc-5888022da351"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i\n",
            "am\n",
            "going\n",
            "to\n",
            "[[16134 14658 22200    73    79  1417  1420  1420  1420  1420]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "array_to_str(prediction[0], vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Eg0NuONaE-yk",
        "outputId": "4bf67056-fed6-42eb-ff81-1001bc7c025d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'be a h ) . <eol> = = = ='"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "aJUamw_cGxUE"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "LSTM_training_new.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}